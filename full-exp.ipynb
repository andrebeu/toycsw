{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# full exp:\n",
    "- gridsearch blocked/interleaved, using MSE human as eval metric\n",
    "    - fix parameters\n",
    "- eval fit on early/middle/late conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# handheld splitting, RNN schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load human data for fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200,), dict_keys(['blocked', 'interleaved', 'early', 'middle', 'late']))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "humandf = pd.read_csv('humandf.csv')\n",
    "human_accD = {}\n",
    "condL =['blocked','interleaved','early','middle','late']\n",
    "for cond in condL:\n",
    "    human_accD[cond] = humandf.loc[:,'%s mean'%cond].values\n",
    "# 1d arrs of acc\n",
    "human_accD['blocked'].shape,human_accD.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### experiment funs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_exp(nseeds,condL,paramD,ntr=160,nte=40):\n",
    "    \"\"\" returns acc for cond in condL \"\"\"\n",
    "    print('N=%i'%nseeds,paramD)\n",
    "    acc = -np.ones([len(condL),nseeds,ntr+nte])\n",
    "    for ci,cond in enumerate(condL):\n",
    "        for s in range(nseeds):\n",
    "            # seed ctrl\n",
    "            np.random.seed(s)\n",
    "            tr.manual_seed(s)\n",
    "            # init\n",
    "            ag = Agent(**paramD)\n",
    "            task = Task()\n",
    "            # run\n",
    "            exp,cur = task.generate_experiment(cond,ntr,nte)\n",
    "            acc[ci,s] = ag.forward_exp(exp) \n",
    "    return acc\n",
    "\n",
    "  \n",
    "def calc_fit(accL,condL):\n",
    "    \"\"\" \n",
    "    accL is arr [cond,seed,trials]\n",
    "    NOTE: CURRENTLY FITTING ON ZSCORED\n",
    "    calcualte mean squared error for model fit\n",
    "    returns mse per condition\n",
    "    \"\"\"\n",
    "    MSE = 0\n",
    "    for model_acc,cond in zip(accL,condL):\n",
    "        human_acc = human_accD[cond]\n",
    "        # mean over seeds -> [trials]\n",
    "        model_acc = model_acc.mean(0) \n",
    "        # zscore\n",
    "        model_zacc = zscore(model_acc)\n",
    "        human_zacc = zscore(human_acc)\n",
    "        # mse\n",
    "        MSE += np.sum((human_zacc - model_zacc)**2)\n",
    "    return MSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gridsearch free params:\n",
    "\n",
    "- sticky_decay_rate\n",
    "- pe_thresh \n",
    "- init_lr \n",
    "- lr_decay_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paramD_to_fname(paramD):\n",
    "  return \"-\".join([\"%s_%f\"%(i,j) for i,j in paramD.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncond 700\n"
     ]
    }
   ],
   "source": [
    "nseeds_gs = 20\n",
    "# gridsearch\n",
    "condBI = ['blocked','interleaved']\n",
    "Sd = np.arange(0.02,0.051,0.005)\n",
    "Pt = np.arange(0.8,1.11,0.1)\n",
    "L0 = np.arange(0.25,0.451,0.05)\n",
    "Ld = np.arange(0.05,0.251,0.05)\n",
    "print('ncond',len(Sd)*len(Pt)*len(L0)*len(Ld))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=20 {'sticky_decay': 0.02, 'pe_thresh': 0.8, 'init_lr': 0.25, 'lr_decay': 0.05}\n"
     ]
    }
   ],
   "source": [
    "gs_results = []\n",
    "for sd,pt,l0,ld in itertools.product(Sd,Pt,L0,Ld):\n",
    "    paramD = {\n",
    "      'sticky_decay':sd,\n",
    "      'pe_thresh':pt,\n",
    "      'init_lr':l0,\n",
    "      'lr_decay':ld,\n",
    "    }\n",
    "    acc = run_exp(nseeds_gs,condBI,paramD)\n",
    "    mse = calc_fit(acc,condBI)\n",
    "    gs_results.append({**paramD,'mse':mse})\n",
    "    if saving:\n",
    "      fname = paramD_to_fname(paramD)\n",
    "      np.save(\"gsdata/\"+fname,acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get best fit\n",
    "bestparamD = pd.DataFrame(gs_results\n",
    "              ).sort_values('mse').iloc[0].to_dict()\n",
    "bestparamD.pop('mse')\n",
    "bestparamD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis of best fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = 20\n",
    "acc_bestBI = run_exp(nseeds=ns,\n",
    "              condL=condBI,\n",
    "              paramD=bestparamD\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### blocked / interleaved plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_human(ax=None,condL=['blocked'],c='k'):\n",
    "  for cond in condL:\n",
    "    ax.plot(human_accD[cond],\n",
    "            c=c,zorder=-99,alpha=0.4\n",
    "           )\n",
    "  return None\n",
    "\n",
    "def plt_acc(acc,condL,ax=None,h=1):\n",
    "  # model\n",
    "  for ac in acc:\n",
    "    ax.plot(ac.mean(0))\n",
    "  # human plot\n",
    "  if h:\n",
    "    plt_human(ax=ax,condL=condL)\n",
    "  ax.set_ylim(0.2,1)    \n",
    "  return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(10,4))\n",
    "ax = plt.gca()\n",
    "plt_acc(acc_bestBI,condBI,ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### early / middle / late plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condEML=['early','middle','late']\n",
    "ns = 20\n",
    "acc_bestEML = run_exp(nseeds=ns,\n",
    "              condL=condEML,\n",
    "              paramD=bestparamD\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(3,1,figsize=(10,10),sharex=True)\n",
    "for ci in range(3):\n",
    "  cond = condEML[ci]\n",
    "  plt_acc([acc_bestEML[ci]],[cond],ax=ax[ci])\n",
    "  ax[ci].set_title(cond)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
